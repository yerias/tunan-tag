# Event Log
#spark.eventLog.enabled="true"
#spark.eventLog.dir="hdfs://aliyun:9000/spark/eventLogs"
#spark.eventLog.compress="true"
# Spark on YARN
#spark.yarn.historyServer.address="http://aliyun:18080"
#spark.yarn.jars="hdfs://aliyun:9000/spark/jars/*"


# KryoSerializer
#spark.serializer=org.apache.spark.serializer.KryoSerializer
# spark.kryo.classesToRegister=org.apache.hadoop.hbase.io.ImmutableBytesWritable,org.apache.hadoop.hbase.client.Result,org.apache.hadoop.hbase.client.Put

# Shuffle Partitions
#spark.sql.shuffle.partitions=4
# broadcasting
#spark.sql.autoBroadcastJoinThreshold=10
# speculation
#spark.speculation=true
# Hive MetaStore
#is.hive=true
#hive.metastore.uris=thrift://aliyun:9083
# Spark Warehouse
#spark.sql.warehouse.dir=hdfs://aliyun:9000/user/hive/warehouse